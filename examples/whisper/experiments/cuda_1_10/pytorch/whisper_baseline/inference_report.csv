experiment_name,backend._target_,backend.name,backend.version,backend.provider,backend.use_io_binding,backend.enable_profiling,backend.inter_op_num_threads,backend.intra_op_num_threads,backend.optimization,backend.optimization_config.optimization_level,backend.optimization_config.optimize_for_gpu,backend.optimization_config.fp16,backend.optimization_config.enable_transformers_specific_optimizations,backend.optimization_config.enable_gelu_approximation,backend.optimization_config.disable_gelu_fusion,backend.optimization_config.disable_layer_norm_fusion,backend.optimization_config.disable_attention_fusion,backend.optimization_config.disable_skip_layer_norm_fusion,backend.optimization_config.disable_bias_skip_layer_norm_fusion,backend.optimization_config.disable_bias_gelu_fusion,backend.optimization_config.use_mask_index,backend.optimization_config.no_attention_mask,backend.optimization_config.disable_embed_layer_norm_fusion,backend.optimization_config.disable_shape_inference,backend.optimization_config.use_multi_head_attention,backend.optimization_config.enable_gemm_fast_gelu_fusion,backend.optimization_config.use_raw_attention_mask,backend.optimization_config.disable_group_norm_fusion,backend.optimization_config.disable_packed_kv,backend.auto_optimization,backend.auto_optimization_config.for_gpu,backend.quantization,backend.quantization_config.is_static,backend.quantization_config.format,backend.quantization_config.mode,backend.quantization_config.activations_dtype,backend.quantization_config.activations_symmetric,backend.quantization_config.weights_dtype,backend.quantization_config.weights_symmetric,backend.quantization_config.per_channel,backend.quantization_config.reduce_range,backend.auto_quantization,backend.auto_quantization_config.is_static,benchmark._target_,benchmark.name,benchmark.profile,benchmark.memory,benchmark.warmup_runs,benchmark.benchmark_duration,benchmark.batch_size,benchmark.new_tokens,model,task,device,experiment_datetime,environment.optimum_version,environment.transformers_version,environment.python_version,environment.system,environment.architecture,environment.machine,environment.cpu,environment.cpu_count,environment.cpu_ram_mb,environment.gpu,environment.gpu_ram_mb,forward.latency(s),forward.throughput(iter/s),generate.throughput(tok/s),backend.disable_grad,backend.eval_mode,backend.bettertransformer,backend.torch_compile,backend.fp16,Model.Speedup(%),Generation.Speedup(%),experiment_name
whisper_auto_opt(O4),src.backend.onnxruntime.ORTBackend,onnxruntime,1.15.0,CUDAExecutionProvider,True,False,,,False,1.0,True,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,O4,True,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,,False,src.benchmark.inference.InferenceBenchmark,inference,False,False,10,10,1,10,openai/whisper-base,automatic-speech-recognition,cuda,2023-06-07_13:49:56,1.8.7.dev0,4.29.2,3.10.11,Linux,64bit,x86_64,x86_64,2,12982,Tesla T4,15360,0.0101,98.6,204.0,,,,,,309.12863070539413,83.78378378378379,whisper_auto_opt(O4)
whisper_auto_opt(O3),src.backend.onnxruntime.ORTBackend,onnxruntime,1.15.0,CUDAExecutionProvider,True,False,,,False,1.0,True,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,O3,True,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,,False,src.benchmark.inference.InferenceBenchmark,inference,False,False,10,10,1,10,openai/whisper-base,automatic-speech-recognition,cuda,2023-06-07_13:49:56,1.8.7.dev0,4.29.2,3.10.11,Linux,64bit,x86_64,x86_64,2,12982,Tesla T4,15360,0.0346,28.9,153.0,,,,,,19.917012448132777,37.83783783783783,whisper_auto_opt(O3)
whisper_auto_opt(O2),src.backend.onnxruntime.ORTBackend,onnxruntime,1.15.0,CUDAExecutionProvider,True,False,,,False,1.0,True,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,O2,True,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,,False,src.benchmark.inference.InferenceBenchmark,inference,False,False,10,10,1,10,openai/whisper-base,automatic-speech-recognition,cuda,2023-06-07_13:49:56,1.8.7.dev0,4.29.2,3.10.11,Linux,64bit,x86_64,x86_64,2,12982,Tesla T4,15360,0.0347,28.8,143.0,,,,,,19.50207468879668,28.828828828828822,whisper_auto_opt(O2)
whisper_auto_opt(O1),src.backend.onnxruntime.ORTBackend,onnxruntime,1.15.0,CUDAExecutionProvider,True,False,,,False,1.0,True,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,O1,True,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,,False,src.benchmark.inference.InferenceBenchmark,inference,False,False,10,10,1,10,openai/whisper-base,automatic-speech-recognition,cuda,2023-06-07_13:49:56,1.8.7.dev0,4.29.2,3.10.11,Linux,64bit,x86_64,x86_64,2,12982,Tesla T4,15360,0.0405,24.7,129.0,,,,,,2.4896265560165887,16.216216216216207,whisper_auto_opt(O1)
whisper_baseline_with_fp16,src.backend.pytorch.PyTorchBackend,pytorch,2.0.1+cu118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,src.benchmark.inference.InferenceBenchmark,inference,False,False,10,10,1,10,openai/whisper-base,automatic-speech-recognition,cuda,2023-06-07_13:47:49,1.8.7.dev0,4.29.2,3.10.11,Linux,64bit,x86_64,x86_64,2,12982,Tesla T4,15360,0.0282,35.4,108.0,True,True,False,False,True,46.88796680497924,-2.7027027027026973,whisper_baseline_with_fp16
whisper_baseline,src.backend.pytorch.PyTorchBackend,pytorch,2.0.1+cu118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,src.benchmark.inference.InferenceBenchmark,inference,False,False,10,10,1,10,openai/whisper-base,automatic-speech-recognition,cuda,2023-06-07_13:45:32,1.8.7.dev0,4.29.2,3.10.11,Linux,64bit,x86_64,x86_64,2,12982,Tesla T4,15360,0.0415,24.1,111.0,True,True,False,False,False,0.0,0.0,whisper_baseline
