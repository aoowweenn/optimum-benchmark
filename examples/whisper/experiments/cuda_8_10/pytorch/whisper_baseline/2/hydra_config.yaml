backend:
  name: pytorch
  version: 2.0.1+cu118
  inter_op_num_threads: null
  intra_op_num_threads: null
  _target_: src.backend.pytorch.PyTorchBackend
  disable_grad: false
  eval_mode: false
  fp16: false
  bettertransformer: false
  torch_compile: false
benchmark:
  name: inference
  _target_: src.benchmark.inference.InferenceBenchmark
  seed: 42
  memory: false
  profile: false
  warmup_runs: 10
  benchmark_duration: 10
  batch_size: 8
  new_tokens: 10
experiment_name: whisper_baseline
model: openai/whisper-base
device: cuda
task: automatic-speech-recognition
environment:
  optimum_version: 1.8.8.dev0
  transformers_version: 4.29.2
  python_version: 3.10.12
  system: Linux
  cpu: ' Intel(R) Xeon(R) CPU @ 2.30GHz'
  cpu_count: 2
  cpu_ram_mb: 12982
  gpu: Tesla T4
  gpu_vram_mb: 15360
