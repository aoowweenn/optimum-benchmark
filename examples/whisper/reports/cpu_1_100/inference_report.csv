experiment_name,backend._target_,backend.name,backend.version,backend.provider,backend.use_io_binding,backend.enable_profiling,backend.inter_op_num_threads,backend.intra_op_num_threads,backend.optimization,backend.optimization_config.optimization_level,backend.optimization_config.optimize_for_gpu,backend.optimization_config.fp16,backend.optimization_config.enable_transformers_specific_optimizations,backend.optimization_config.enable_gelu_approximation,backend.optimization_config.disable_gelu_fusion,backend.optimization_config.disable_layer_norm_fusion,backend.optimization_config.disable_attention_fusion,backend.optimization_config.disable_skip_layer_norm_fusion,backend.optimization_config.disable_bias_skip_layer_norm_fusion,backend.optimization_config.disable_bias_gelu_fusion,backend.optimization_config.use_mask_index,backend.optimization_config.no_attention_mask,backend.optimization_config.disable_embed_layer_norm_fusion,backend.optimization_config.disable_shape_inference,backend.optimization_config.use_multi_head_attention,backend.optimization_config.enable_gemm_fast_gelu_fusion,backend.optimization_config.use_raw_attention_mask,backend.optimization_config.disable_group_norm_fusion,backend.optimization_config.disable_packed_kv,backend.auto_optimization,backend.auto_optimization_config.for_gpu,backend.quantization,backend.quantization_config.is_static,backend.quantization_config.format,backend.quantization_config.mode,backend.quantization_config.activations_dtype,backend.quantization_config.activations_symmetric,backend.quantization_config.weights_dtype,backend.quantization_config.weights_symmetric,backend.quantization_config.per_channel,backend.quantization_config.reduce_range,backend.quantization_config.operators_to_quantize,backend.auto_quantization,backend.auto_quantization_config.is_static,backend.auto_quantization_config.per_channel,benchmark._target_,benchmark.name,benchmark.profile,benchmark.memory,benchmark.warmup_runs,benchmark.benchmark_duration,benchmark.batch_size,benchmark.new_tokens,model,task,device,experiment_datetime,environment.optimum_version,environment.transformers_version,environment.python_version,environment.system,environment.architecture,environment.machine,environment.cpu,environment.cpu_count,environment.cpu_ram_mb,environment.gpu,environment.gpu_ram_mb,Unnamed: 0,forward.latency(s),forward.throughput(iter/s),generate.throughput(tok/s),backend.auto_quantization_config.operators_to_quantize,backend.disable_grad,backend.eval_mode,backend.bettertransformer,backend.torch_compile,backend.fp16,forward.speedup(%),generate.speedup(%)
whisper_auto_opt(O3)+auto_qnt(avx512),src.backend.onnxruntime.ORTBackend,onnxruntime,1.15.0,CPUExecutionProvider,False,False,,,False,1,False,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,O3,False,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,"['MatMul', 'Add']",avx512,False,False,src.benchmark.inference.InferenceBenchmark,inference,False,False,10,10,1,100,openai/whisper-base,automatic-speech-recognition,cpu,2023-06-07_11:10:54,1.8.7.dev0,4.29.2,3.10.11,Linux,64bit,x86_64,x86_64,2,12982,CUDA not available,CUDA not available,0,1.68,0.596,23.4,"['Gather', 'Transpose', 'EmbedLayerNormalization', 'Attention', 'LSTM', 'ArgMax', 'Gemm', 'MatMul', 'Add', 'Mul', 'Relu', 'Clip', 'LeakyRelu', 'Sigmoid', 'MaxPool', 'GlobalAveragePool', 'Split', 'Pad', 'Reshape', 'Squeeze', 'Unsqueeze', 'Resize', 'AveragePool', 'Concat', 'Softmax', 'Where', 'ConvTranspose', 'InstanceNormalization']",,,,,,65.55555555555554,58.10810810810809
whisper_auto_qnt(avx512_vnni),src.backend.onnxruntime.ORTBackend,onnxruntime,1.15.0,CPUExecutionProvider,False,False,,,False,1,False,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,,False,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,"['MatMul', 'Add']",avx512_vnni,False,False,src.benchmark.inference.InferenceBenchmark,inference,False,False,10,10,1,100,openai/whisper-base,automatic-speech-recognition,cpu,2023-06-07_09:42:57,1.8.7.dev0,4.29.2,3.10.11,Linux,64bit,x86_64,x86_64,2,12982,CUDA not available,CUDA not available,0,1.73,0.577,22.9,,,,,,,60.277777777777764,54.72972972972971
whisper_auto_opt(O1)+auto_qnt(avx512),src.backend.onnxruntime.ORTBackend,onnxruntime,1.15.0,CPUExecutionProvider,False,False,,,False,1,False,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,O1,False,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,"['MatMul', 'Add']",avx512,False,False,src.benchmark.inference.InferenceBenchmark,inference,False,False,10,10,1,100,openai/whisper-base,automatic-speech-recognition,cpu,2023-06-07_11:10:54,1.8.7.dev0,4.29.2,3.10.11,Linux,64bit,x86_64,x86_64,2,12982,CUDA not available,CUDA not available,0,1.95,0.513,21.7,"['Gather', 'Transpose', 'EmbedLayerNormalization', 'Attention', 'LSTM', 'ArgMax', 'Gemm', 'MatMul', 'Add', 'Mul', 'Relu', 'Clip', 'LeakyRelu', 'Sigmoid', 'MaxPool', 'GlobalAveragePool', 'Split', 'Pad', 'Reshape', 'Squeeze', 'Unsqueeze', 'Resize', 'AveragePool', 'Concat', 'Softmax', 'Where', 'ConvTranspose', 'InstanceNormalization']",,,,,,42.50000000000001,46.6216216216216
whisper_auto_opt(O1)+auto_qnt(arm64),src.backend.onnxruntime.ORTBackend,onnxruntime,1.15.0,CPUExecutionProvider,False,False,,,False,1,False,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,O1,False,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,"['MatMul', 'Add']",arm64,False,False,src.benchmark.inference.InferenceBenchmark,inference,False,False,10,10,1,100,openai/whisper-base,automatic-speech-recognition,cpu,2023-06-07_11:10:54,1.8.7.dev0,4.29.2,3.10.11,Linux,64bit,x86_64,x86_64,2,12982,CUDA not available,CUDA not available,0,1.95,0.512,23.2,"['Gather', 'Transpose', 'EmbedLayerNormalization', 'Attention', 'LSTM', 'ArgMax', 'Gemm', 'MatMul', 'Add', 'Mul', 'Relu', 'Clip', 'LeakyRelu', 'Sigmoid', 'MaxPool', 'GlobalAveragePool', 'Split', 'Pad', 'Reshape', 'Squeeze', 'Unsqueeze', 'Resize', 'AveragePool', 'Concat', 'Softmax', 'Where', 'ConvTranspose', 'InstanceNormalization']",,,,,,42.22222222222223,56.75675675675676
whisper_auto_opt(O2)+auto_qnt(avx2),src.backend.onnxruntime.ORTBackend,onnxruntime,1.15.0,CPUExecutionProvider,False,False,,,False,1,False,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,O2,False,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,"['MatMul', 'Add']",avx2,False,False,src.benchmark.inference.InferenceBenchmark,inference,False,False,10,10,1,100,openai/whisper-base,automatic-speech-recognition,cpu,2023-06-07_11:10:54,1.8.7.dev0,4.29.2,3.10.11,Linux,64bit,x86_64,x86_64,2,12982,CUDA not available,CUDA not available,0,2.02,0.496,19.8,"['Gather', 'Transpose', 'EmbedLayerNormalization', 'Attention', 'LSTM', 'ArgMax', 'Gemm', 'MatMul', 'Add', 'Mul', 'Relu', 'Clip', 'LeakyRelu', 'Sigmoid', 'MaxPool', 'GlobalAveragePool', 'Split', 'Pad', 'Reshape', 'Squeeze', 'Unsqueeze', 'Resize', 'AveragePool', 'Concat', 'Softmax', 'Where', 'ConvTranspose', 'InstanceNormalization']",,,,,,37.77777777777778,33.783783783783775
whisper_auto_opt(O2)+auto_qnt(arm64),src.backend.onnxruntime.ORTBackend,onnxruntime,1.15.0,CPUExecutionProvider,False,False,,,False,1,False,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,O2,False,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,"['MatMul', 'Add']",arm64,False,False,src.benchmark.inference.InferenceBenchmark,inference,False,False,10,10,1,100,openai/whisper-base,automatic-speech-recognition,cpu,2023-06-07_11:10:54,1.8.7.dev0,4.29.2,3.10.11,Linux,64bit,x86_64,x86_64,2,12982,CUDA not available,CUDA not available,0,2.06,0.485,20.7,"['Gather', 'Transpose', 'EmbedLayerNormalization', 'Attention', 'LSTM', 'ArgMax', 'Gemm', 'MatMul', 'Add', 'Mul', 'Relu', 'Clip', 'LeakyRelu', 'Sigmoid', 'MaxPool', 'GlobalAveragePool', 'Split', 'Pad', 'Reshape', 'Squeeze', 'Unsqueeze', 'Resize', 'AveragePool', 'Concat', 'Softmax', 'Where', 'ConvTranspose', 'InstanceNormalization']",,,,,,34.72222222222223,39.86486486486485
whisper_auto_qnt(avx512),src.backend.onnxruntime.ORTBackend,onnxruntime,1.15.0,CPUExecutionProvider,False,False,,,False,1,False,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,,False,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,"['MatMul', 'Add']",avx512,False,False,src.benchmark.inference.InferenceBenchmark,inference,False,False,10,10,1,100,openai/whisper-base,automatic-speech-recognition,cpu,2023-06-07_09:42:57,1.8.7.dev0,4.29.2,3.10.11,Linux,64bit,x86_64,x86_64,2,12982,CUDA not available,CUDA not available,0,2.06,0.484,17.6,,,,,,,34.44444444444446,18.918918918918926
whisper_auto_opt(O2)+auto_qnt(avx512_vnni),src.backend.onnxruntime.ORTBackend,onnxruntime,1.15.0,CPUExecutionProvider,False,False,,,False,1,False,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,O2,False,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,"['MatMul', 'Add']",avx512_vnni,False,False,src.benchmark.inference.InferenceBenchmark,inference,False,False,10,10,1,100,openai/whisper-base,automatic-speech-recognition,cpu,2023-06-07_11:10:54,1.8.7.dev0,4.29.2,3.10.11,Linux,64bit,x86_64,x86_64,2,12982,CUDA not available,CUDA not available,0,2.15,0.465,19.5,"['Gather', 'Transpose', 'EmbedLayerNormalization', 'Attention', 'LSTM', 'ArgMax', 'Gemm', 'MatMul', 'Add', 'Mul', 'Relu', 'Clip', 'LeakyRelu', 'Sigmoid', 'MaxPool', 'GlobalAveragePool', 'Split', 'Pad', 'Reshape', 'Squeeze', 'Unsqueeze', 'Resize', 'AveragePool', 'Concat', 'Softmax', 'Where', 'ConvTranspose', 'InstanceNormalization']",,,,,,29.166666666666675,31.756756756756754
whisper_auto_opt(O2)+auto_qnt(avx512),src.backend.onnxruntime.ORTBackend,onnxruntime,1.15.0,CPUExecutionProvider,False,False,,,False,1,False,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,O2,False,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,"['MatMul', 'Add']",avx512,False,False,src.benchmark.inference.InferenceBenchmark,inference,False,False,10,10,1,100,openai/whisper-base,automatic-speech-recognition,cpu,2023-06-07_11:10:54,1.8.7.dev0,4.29.2,3.10.11,Linux,64bit,x86_64,x86_64,2,12982,CUDA not available,CUDA not available,0,2.17,0.461,19.5,"['Gather', 'Transpose', 'EmbedLayerNormalization', 'Attention', 'LSTM', 'ArgMax', 'Gemm', 'MatMul', 'Add', 'Mul', 'Relu', 'Clip', 'LeakyRelu', 'Sigmoid', 'MaxPool', 'GlobalAveragePool', 'Split', 'Pad', 'Reshape', 'Squeeze', 'Unsqueeze', 'Resize', 'AveragePool', 'Concat', 'Softmax', 'Where', 'ConvTranspose', 'InstanceNormalization']",,,,,,28.055555555555568,31.756756756756754
whisper_auto_opt(O1),src.backend.onnxruntime.ORTBackend,onnxruntime,1.15.0,CPUExecutionProvider,False,False,,,False,1,False,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,O1,False,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,"['MatMul', 'Add']",,False,,src.benchmark.inference.InferenceBenchmark,inference,False,False,10,10,1,100,openai/whisper-base,automatic-speech-recognition,cpu,2023-06-07_10:04:36,1.8.7.dev0,4.29.2,3.10.11,Linux,64bit,x86_64,x86_64,2,12982,CUDA not available,CUDA not available,0,2.23,0.448,19.9,,,,,,,24.444444444444446,34.45945945945945
whisper_auto_opt(O1)+auto_qnt(avx512_vnni),src.backend.onnxruntime.ORTBackend,onnxruntime,1.15.0,CPUExecutionProvider,False,False,,,False,1,False,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,O1,False,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,"['MatMul', 'Add']",avx512_vnni,False,False,src.benchmark.inference.InferenceBenchmark,inference,False,False,10,10,1,100,openai/whisper-base,automatic-speech-recognition,cpu,2023-06-07_11:10:54,1.8.7.dev0,4.29.2,3.10.11,Linux,64bit,x86_64,x86_64,2,12982,CUDA not available,CUDA not available,0,2.25,0.445,20.7,"['Gather', 'Transpose', 'EmbedLayerNormalization', 'Attention', 'LSTM', 'ArgMax', 'Gemm', 'MatMul', 'Add', 'Mul', 'Relu', 'Clip', 'LeakyRelu', 'Sigmoid', 'MaxPool', 'GlobalAveragePool', 'Split', 'Pad', 'Reshape', 'Squeeze', 'Unsqueeze', 'Resize', 'AveragePool', 'Concat', 'Softmax', 'Where', 'ConvTranspose', 'InstanceNormalization']",,,,,,23.611111111111114,39.86486486486485
whisper_auto_opt(O1)+auto_qnt(avx2),src.backend.onnxruntime.ORTBackend,onnxruntime,1.15.0,CPUExecutionProvider,False,False,,,False,1,False,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,O1,False,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,"['MatMul', 'Add']",avx2,False,False,src.benchmark.inference.InferenceBenchmark,inference,False,False,10,10,1,100,openai/whisper-base,automatic-speech-recognition,cpu,2023-06-07_11:10:54,1.8.7.dev0,4.29.2,3.10.11,Linux,64bit,x86_64,x86_64,2,12982,CUDA not available,CUDA not available,0,2.25,0.445,20.7,"['Gather', 'Transpose', 'EmbedLayerNormalization', 'Attention', 'LSTM', 'ArgMax', 'Gemm', 'MatMul', 'Add', 'Mul', 'Relu', 'Clip', 'LeakyRelu', 'Sigmoid', 'MaxPool', 'GlobalAveragePool', 'Split', 'Pad', 'Reshape', 'Squeeze', 'Unsqueeze', 'Resize', 'AveragePool', 'Concat', 'Softmax', 'Where', 'ConvTranspose', 'InstanceNormalization']",,,,,,23.611111111111114,39.86486486486485
whisper_auto_opt(O3)+auto_qnt(avx2),src.backend.onnxruntime.ORTBackend,onnxruntime,1.15.0,CPUExecutionProvider,False,False,,,False,1,False,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,O3,False,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,"['MatMul', 'Add']",avx2,False,False,src.benchmark.inference.InferenceBenchmark,inference,False,False,10,10,1,100,openai/whisper-base,automatic-speech-recognition,cpu,2023-06-07_11:10:54,1.8.7.dev0,4.29.2,3.10.11,Linux,64bit,x86_64,x86_64,2,12982,CUDA not available,CUDA not available,0,2.36,0.423,19.3,"['Gather', 'Transpose', 'EmbedLayerNormalization', 'Attention', 'LSTM', 'ArgMax', 'Gemm', 'MatMul', 'Add', 'Mul', 'Relu', 'Clip', 'LeakyRelu', 'Sigmoid', 'MaxPool', 'GlobalAveragePool', 'Split', 'Pad', 'Reshape', 'Squeeze', 'Unsqueeze', 'Resize', 'AveragePool', 'Concat', 'Softmax', 'Where', 'ConvTranspose', 'InstanceNormalization']",,,,,,17.500000000000004,30.405405405405396
whisper_auto_qnt(avx2),src.backend.onnxruntime.ORTBackend,onnxruntime,1.15.0,CPUExecutionProvider,False,False,,,False,1,False,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,,False,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,"['MatMul', 'Add']",avx2,False,False,src.benchmark.inference.InferenceBenchmark,inference,False,False,10,10,1,100,openai/whisper-base,automatic-speech-recognition,cpu,2023-06-07_09:42:57,1.8.7.dev0,4.29.2,3.10.11,Linux,64bit,x86_64,x86_64,2,12982,CUDA not available,CUDA not available,0,2.39,0.418,19.8,,,,,,,16.11111111111112,33.783783783783775
whisper_auto_opt(O3),src.backend.onnxruntime.ORTBackend,onnxruntime,1.15.0,CPUExecutionProvider,False,False,,,False,1,False,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,O3,False,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,"['MatMul', 'Add']",,False,,src.benchmark.inference.InferenceBenchmark,inference,False,False,10,10,1,100,openai/whisper-base,automatic-speech-recognition,cpu,2023-06-07_10:04:36,1.8.7.dev0,4.29.2,3.10.11,Linux,64bit,x86_64,x86_64,2,12982,CUDA not available,CUDA not available,0,2.55,0.392,18.2,,,,,,,8.888888888888902,22.97297297297296
whisper_auto_opt(O3)+auto_qnt(arm64),src.backend.onnxruntime.ORTBackend,onnxruntime,1.15.0,CPUExecutionProvider,False,False,,,False,1,False,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,O3,False,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,"['MatMul', 'Add']",arm64,False,False,src.benchmark.inference.InferenceBenchmark,inference,False,False,10,10,1,100,openai/whisper-base,automatic-speech-recognition,cpu,2023-06-07_11:10:54,1.8.7.dev0,4.29.2,3.10.11,Linux,64bit,x86_64,x86_64,2,12982,CUDA not available,CUDA not available,0,2.59,0.386,20.5,"['Gather', 'Transpose', 'EmbedLayerNormalization', 'Attention', 'LSTM', 'ArgMax', 'Gemm', 'MatMul', 'Add', 'Mul', 'Relu', 'Clip', 'LeakyRelu', 'Sigmoid', 'MaxPool', 'GlobalAveragePool', 'Split', 'Pad', 'Reshape', 'Squeeze', 'Unsqueeze', 'Resize', 'AveragePool', 'Concat', 'Softmax', 'Where', 'ConvTranspose', 'InstanceNormalization']",,,,,,7.222222222222219,38.51351351351351
whisper_auto_opt(O2),src.backend.onnxruntime.ORTBackend,onnxruntime,1.15.0,CPUExecutionProvider,False,False,,,False,1,False,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,O2,False,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,"['MatMul', 'Add']",,False,,src.benchmark.inference.InferenceBenchmark,inference,False,False,10,10,1,100,openai/whisper-base,automatic-speech-recognition,cpu,2023-06-07_10:04:36,1.8.7.dev0,4.29.2,3.10.11,Linux,64bit,x86_64,x86_64,2,12982,CUDA not available,CUDA not available,0,2.66,0.376,10.9,,,,,,,4.444444444444451,-26.351351351351347
whisper_auto_opt(O4),src.backend.onnxruntime.ORTBackend,onnxruntime,1.15.0,CPUExecutionProvider,False,False,,,False,1,False,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,O4,False,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,"['MatMul', 'Add']",,False,,src.benchmark.inference.InferenceBenchmark,inference,False,False,10,10,1,100,openai/whisper-base,automatic-speech-recognition,cpu,2023-06-07_10:04:36,1.8.7.dev0,4.29.2,3.10.11,Linux,64bit,x86_64,x86_64,2,12982,CUDA not available,CUDA not available,0,2.98,0.336,5.11,,,,,,,-6.666666666666654,-65.47297297297297
whisper_auto_qnt(arm64),src.backend.onnxruntime.ORTBackend,onnxruntime,1.15.0,CPUExecutionProvider,False,False,,,False,1,False,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,,False,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,"['MatMul', 'Add']",arm64,False,False,src.benchmark.inference.InferenceBenchmark,inference,False,False,10,10,1,100,openai/whisper-base,automatic-speech-recognition,cpu,2023-06-07_09:42:57,1.8.7.dev0,4.29.2,3.10.11,Linux,64bit,x86_64,x86_64,2,12982,CUDA not available,CUDA not available,0,3.46,0.289,19.5,,,,,,,-19.72222222222223,31.756756756756754
whisper_auto_opt(O3)+auto_qnt(avx512_vnni),src.backend.onnxruntime.ORTBackend,onnxruntime,1.15.0,CPUExecutionProvider,False,False,,,False,1,False,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,O3,False,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,"['MatMul', 'Add']",avx512_vnni,False,False,src.benchmark.inference.InferenceBenchmark,inference,False,False,10,10,1,100,openai/whisper-base,automatic-speech-recognition,cpu,2023-06-07_11:10:54,1.8.7.dev0,4.29.2,3.10.11,Linux,64bit,x86_64,x86_64,2,12982,CUDA not available,CUDA not available,0,3.85,0.26,19.8,"['Gather', 'Transpose', 'EmbedLayerNormalization', 'Attention', 'LSTM', 'ArgMax', 'Gemm', 'MatMul', 'Add', 'Mul', 'Relu', 'Clip', 'LeakyRelu', 'Sigmoid', 'MaxPool', 'GlobalAveragePool', 'Split', 'Pad', 'Reshape', 'Squeeze', 'Unsqueeze', 'Resize', 'AveragePool', 'Concat', 'Softmax', 'Where', 'ConvTranspose', 'InstanceNormalization']",,,,,,-27.777777777777768,33.783783783783775
whisper_baseline,src.backend.pytorch.PyTorchBackend,pytorch,2.0.1+cu118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,src.benchmark.inference.InferenceBenchmark,inference,False,False,10,10,1,100,openai/whisper-base,automatic-speech-recognition,cpu,2023-06-07_09:39:31,1.8.7.dev0,4.29.2,3.10.11,Linux,64bit,x86_64,x86_64,2,12982,CUDA not available,CUDA not available,0,2.78,0.36,14.8,,True,True,False,False,False,0.0,0.0
